# Behin the scenes: Investigating the Investigators 2019

## Categories

    - rambles
    - technical tidbits
    - for scientists
## Tags

    - career, coding, ECR, lessons, python, research, scicomm, science


## Introduction



## Raw data

The raw data used in this analysis came from three main sources.

The first was the [NHMRC grant outcomes website](https://www.nhmrc.gov.au/funding/data-research/outcomes-funding-rounds), which offers spreadsheet summaries for grants released since 2013. I chose to use only the data from 2015 onwards, for a couple of reasons: (1) the structure of the Fellowship system appears to have changed in 2014 to the ECF, CDF, RF layout which remained in place until 2018. This meant that 2013 data was poorly correlated with the more recent datasets. (2) The 2014 dataset did not have as much detail in the gender, age, state breakdowns that could be easily compared to the following years. (3) Five years seemed like a nice time period to work with!

The second source of data was the Field of Research codes used to classify research. You can find the complete list at the [Australian Bureau of Statistics](https://www.abs.gov.au/ausstats/abs@.nsf/0/6BB427AB9696C225CA2574180004463E?opendocument). I struggled to find an easily-downloadable version, and instead copied them from the University of Melbourne intranet. With a little post-processing, I had a fully functional list of each level of classification, which I could then use to understand which types of research were popular for funding.

The last source of data was [Scival](), which I used to gather the number of research publications and average Field-Weighted-Citation-Impact (FWCI) for each awardee in the ten years previous to their year of award. This was somewhat of a manual process, and I used the 'best match' profile for each awardee imported into SciVal. Overally, 88% of the awardees were matched accurately (and this could be increased with a little manual curation). I also did a little digging around in the PubMed Central API using a python package (see the resources list below for more information) to batch-query the author names and collect their publication history, to compare with the matches generated by SciVal. For more details on this process, keep an eye out for my Behind the Scenes post!

### Processing and analysis

After initial cleaning of the raw data, I then equated the new and old schemes by matching the tiers. Although the correlation is imperfect (due to changes to eligibility between the old and new schemes), this resulted in Early Career Fellowships mapping to Emerging Leader 1, Career Development Fellowships mapping to Emerging Leader 2, and Research Fellowships mapping to Leadership Fellowships. I also filtered the publication history to include only those papers published in the year before award.

## Behind the scenes

- Lessons learnt:
  - Data is _messy_
  - People, despite working in science-oriented positions, do not handle, label or store data well
  - Trends are interesting, but should be cautiously interpreted

- Publication history searches are a tricky one
  - Paywalled publication information is a nightmare
  - PubMed searches are OK, but limited - no H-index etc
  - People's names are difficult! Hard to know whether to split into first/last etc

- Why I didn't choose pink and blue for gender studies
  - https://blog.datawrapper.de/gendercolor/

- What on earth is a choropleth and where do I find a shapefile?
  - https://towardsdatascience.com/lets-make-a-map-using-geopandas-pandas-and-matplotlib-to-make-a-chloropleth-map-dddc31c1983d
  - [Geospatial data](https://github.com/rowanhogan/australian-states/blob/master/states.geojson)


- What is fuzzy text matching, and how does Levenshtein help?
  - https://www.datacamp.com/community/tutorials/fuzzy-string-python

## Resources

**Python goodies**
- [pybliometrics](https://github.com/pybliometrics-dev/pybliometrics)
- panel/glueviz
- [pandas](), [seaborn]()
- [MyBinder]()
- [wordcloud](https://github.com/amueller/word_cloud)
- [geopandas]()
- [pingouin]()
- 


***

conclusion

<small>Image credits:</small>
